{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c1c37",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "To get p-values, you have to use a library specifically built for statistical testing, like _SciPy_.\n",
    "\n",
    "`scipy` is the gold standard for scientific computing, but it is designed to calculate the correlation and p-value for one pair of variables at a time. It doesn't have a single \"matrix\" function like `df.corr()`.\n",
    "\n",
    "To create the correlation matrix and get p-values using `scipy`, you need to iterate through your column combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scipy_corrs(df, variables):\n",
    "    n = len(variables)\n",
    "    # Initialize with NaNs to handle cases where calculation fails\n",
    "    p_matrix = np.full((n, n), np.nan)\n",
    "    r_matrix = np.full((n, n), np.nan)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # 1. Select the two columns and drop rows where either is NaN\n",
    "            subset = df[[variables[i], variables[j]]].dropna()\n",
    "            \n",
    "            # 2. Ensure data is numeric and flattened to 1D arrays\n",
    "            x = subset[variables[i]].astype(float).values\n",
    "            y = subset[variables[j]].astype(float).values\n",
    "            \n",
    "            # 3. Calculate (requires at least 2 points for a correlation)\n",
    "            if len(x) > 1:\n",
    "                try:\n",
    "                    res = stats.pearsonr(x, y)\n",
    "                    r_matrix[i, j] = res.statistic\n",
    "                    p_matrix[i, j] = res.pvalue\n",
    "                except:\n",
    "                    continue # Skip pairs that cause math errors (e.g. zero variance)\n",
    "                \n",
    "    # Return as clean DataFrames\n",
    "    r_df = pd.DataFrame(r_matrix, index=variables, columns=variables)\n",
    "    p_df = pd.DataFrame(p_matrix, index=variables, columns=variables)\n",
    "    return r_df, p_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab3c73",
   "metadata": {},
   "source": [
    "Creating a table that follows APA conventions is a little tricky. We've written a function to help you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f17df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_apa_correlation(r_df, p_df):\n",
    "    # Create a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(r_df, dtype=bool))\n",
    "    \n",
    "    # Initialize the formatted DataFrame\n",
    "    apa_df = r_df.copy().astype(str)\n",
    "    \n",
    "    for i in range(len(r_df.index)):\n",
    "        for j in range(len(r_df.columns)):\n",
    "            # Hide the upper triangle and diagonal\n",
    "            if i <= j:\n",
    "                apa_df.iloc[i, j] = \"\"\n",
    "                continue\n",
    "                \n",
    "            r_val = r_df.iloc[i, j]\n",
    "            p_val = p_df.iloc[i, j]\n",
    "            \n",
    "            # Add stars\n",
    "            stars = \"\"\n",
    "            if p_val < .001: stars = \"***\"\n",
    "            elif p_val < .01: stars = \"**\"\n",
    "            elif p_val < .05: stars = \"*\"\n",
    "            \n",
    "            # Format to 2 or 3 decimal places (APA usually uses 2 or 3)\n",
    "            # This version keeps 3 for precision\n",
    "            formatted_r = f\"{r_val:.2f}\".replace(\"0.\", \".\") # Remove leading zero for APA style\n",
    "            apa_df.iloc[i, j] = f\"{formatted_r}{stars}\"\n",
    "            \n",
    "    # Rename columns to 1, 2, 3... to follow APA table headers\n",
    "    apa_df.columns = [f\"{i+1}.\" for i in range(len(apa_df.columns))]\n",
    "    # Add the variable names as the first column\n",
    "    apa_df.insert(0, \"Variable\", r_df.index)\n",
    "    # Add a column for the index numbers\n",
    "    apa_df.insert(0, \"â„–\", range(1, len(apa_df) + 1))\n",
    "    \n",
    "    return apa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed7ab0",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "You'll need to download the data from the link in the assignment on Canvas. The filename you're looking for is `Dawtry Sutton and Sibley 2015 Study 1a.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b251fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dawtry et al. (2015) Study 1a data\n",
    "df = pd.read_csv('')  # Add the correct path to the CSV file here\n",
    "\n",
    "# Explore the dataframe\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\\n{df.head()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
